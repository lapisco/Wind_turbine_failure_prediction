{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports of libraries and frameworks:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "\n",
    "seed = 69\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = '../../datasets/v000_SCIG_SC_SENSORC_FOURIER_010.csv'\n",
    "dataset = pd.read_csv(filename);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>fx1_R</th>\n",
       "      <th>fx0d5_R</th>\n",
       "      <th>fx1d5_R</th>\n",
       "      <th>fx2d5_R</th>\n",
       "      <th>fx3_R</th>\n",
       "      <th>fx5_R</th>\n",
       "      <th>fx7_R</th>\n",
       "      <th>fx1_S</th>\n",
       "      <th>fx0d5_S</th>\n",
       "      <th>...</th>\n",
       "      <th>fx7_T</th>\n",
       "      <th>Freq_Rated</th>\n",
       "      <th>Freq_Gen</th>\n",
       "      <th>CC_bus</th>\n",
       "      <th>Power</th>\n",
       "      <th>I_R_rms</th>\n",
       "      <th>I_S_rms</th>\n",
       "      <th>I_T_rms</th>\n",
       "      <th>Load</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.006626</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>0.023378</td>\n",
       "      <td>0.023553</td>\n",
       "      <td>0.006339</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006059</td>\n",
       "      <td>45.0</td>\n",
       "      <td>43.85</td>\n",
       "      <td>369</td>\n",
       "      <td>0.57</td>\n",
       "      <td>2.906343</td>\n",
       "      <td>2.920356</td>\n",
       "      <td>2.986445</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003416</td>\n",
       "      <td>0.006184</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.023907</td>\n",
       "      <td>0.013409</td>\n",
       "      <td>0.005977</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005722</td>\n",
       "      <td>45.0</td>\n",
       "      <td>43.87</td>\n",
       "      <td>368</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2.885150</td>\n",
       "      <td>2.896358</td>\n",
       "      <td>2.962763</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>0.004380</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.018111</td>\n",
       "      <td>0.011143</td>\n",
       "      <td>0.005009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004889</td>\n",
       "      <td>45.0</td>\n",
       "      <td>43.89</td>\n",
       "      <td>367</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2.851384</td>\n",
       "      <td>2.863890</td>\n",
       "      <td>2.935414</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.019345</td>\n",
       "      <td>0.014027</td>\n",
       "      <td>0.004023</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003913</td>\n",
       "      <td>45.0</td>\n",
       "      <td>43.91</td>\n",
       "      <td>365</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2.819084</td>\n",
       "      <td>2.827510</td>\n",
       "      <td>2.900116</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004993</td>\n",
       "      <td>0.004015</td>\n",
       "      <td>0.001150</td>\n",
       "      <td>0.025392</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>0.004693</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004557</td>\n",
       "      <td>45.0</td>\n",
       "      <td>43.93</td>\n",
       "      <td>363</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2.761420</td>\n",
       "      <td>2.774290</td>\n",
       "      <td>2.844834</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx  fx1_R   fx0d5_R   fx1d5_R   fx2d5_R     fx3_R     fx5_R     fx7_R  \\\n",
       "0    1    1.0  0.007299  0.006626  0.000968  0.023378  0.023553  0.006339   \n",
       "1    2    1.0  0.003416  0.006184  0.001155  0.023907  0.013409  0.005977   \n",
       "2    3    1.0  0.003490  0.004380  0.000786  0.018111  0.011143  0.005009   \n",
       "3    4    1.0  0.002984  0.002304  0.000533  0.019345  0.014027  0.004023   \n",
       "4    5    1.0  0.004993  0.004015  0.001150  0.025392  0.018566  0.004693   \n",
       "\n",
       "   fx1_S   fx0d5_S  ...       fx7_T  Freq_Rated  Freq_Gen  CC_bus  Power  \\\n",
       "0    1.0  0.007219  ...    0.006059        45.0     43.85     369   0.57   \n",
       "1    1.0  0.003368  ...    0.005722        45.0     43.87     368   0.55   \n",
       "2    1.0  0.003484  ...    0.004889        45.0     43.89     367   0.55   \n",
       "3    1.0  0.002979  ...    0.003913        45.0     43.91     365   0.53   \n",
       "4    1.0  0.004956  ...    0.004557        45.0     43.93     363   0.52   \n",
       "\n",
       "    I_R_rms   I_S_rms   I_T_rms  Load  Class  \n",
       "0  2.906343  2.920356  2.986445     0      1  \n",
       "1  2.885150  2.896358  2.962763     0      1  \n",
       "2  2.851384  2.863890  2.935414     0      1  \n",
       "3  2.819084  2.827510  2.900116     0      1  \n",
       "4  2.761420  2.774290  2.844834     0      1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unwanted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fx0d5_R</th>\n",
       "      <th>fx1d5_R</th>\n",
       "      <th>fx2d5_R</th>\n",
       "      <th>fx3_R</th>\n",
       "      <th>fx5_R</th>\n",
       "      <th>fx7_R</th>\n",
       "      <th>fx0d5_S</th>\n",
       "      <th>fx1d5_S</th>\n",
       "      <th>fx2d5_S</th>\n",
       "      <th>fx3_S</th>\n",
       "      <th>...</th>\n",
       "      <th>fx3_T</th>\n",
       "      <th>fx5_T</th>\n",
       "      <th>fx7_T</th>\n",
       "      <th>Freq_Gen</th>\n",
       "      <th>CC_bus</th>\n",
       "      <th>I_R_rms</th>\n",
       "      <th>I_S_rms</th>\n",
       "      <th>I_T_rms</th>\n",
       "      <th>Load</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.006626</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>0.023378</td>\n",
       "      <td>0.023553</td>\n",
       "      <td>0.006339</td>\n",
       "      <td>0.007219</td>\n",
       "      <td>0.006553</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>0.023122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022347</td>\n",
       "      <td>0.022515</td>\n",
       "      <td>0.006059</td>\n",
       "      <td>43.85</td>\n",
       "      <td>369</td>\n",
       "      <td>2.906343</td>\n",
       "      <td>2.920356</td>\n",
       "      <td>2.986445</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003416</td>\n",
       "      <td>0.006184</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.023907</td>\n",
       "      <td>0.013409</td>\n",
       "      <td>0.005977</td>\n",
       "      <td>0.003368</td>\n",
       "      <td>0.006097</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.023569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022888</td>\n",
       "      <td>0.012837</td>\n",
       "      <td>0.005722</td>\n",
       "      <td>43.87</td>\n",
       "      <td>368</td>\n",
       "      <td>2.885150</td>\n",
       "      <td>2.896358</td>\n",
       "      <td>2.962763</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003490</td>\n",
       "      <td>0.004380</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.018111</td>\n",
       "      <td>0.011143</td>\n",
       "      <td>0.005009</td>\n",
       "      <td>0.003484</td>\n",
       "      <td>0.004373</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.018082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017678</td>\n",
       "      <td>0.010877</td>\n",
       "      <td>0.004889</td>\n",
       "      <td>43.89</td>\n",
       "      <td>367</td>\n",
       "      <td>2.851384</td>\n",
       "      <td>2.863890</td>\n",
       "      <td>2.935414</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.019345</td>\n",
       "      <td>0.014027</td>\n",
       "      <td>0.004023</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.019312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018814</td>\n",
       "      <td>0.013642</td>\n",
       "      <td>0.003913</td>\n",
       "      <td>43.91</td>\n",
       "      <td>365</td>\n",
       "      <td>2.819084</td>\n",
       "      <td>2.827510</td>\n",
       "      <td>2.900116</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004993</td>\n",
       "      <td>0.004015</td>\n",
       "      <td>0.001150</td>\n",
       "      <td>0.025392</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>0.004693</td>\n",
       "      <td>0.004956</td>\n",
       "      <td>0.003986</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.025204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024655</td>\n",
       "      <td>0.018027</td>\n",
       "      <td>0.004557</td>\n",
       "      <td>43.93</td>\n",
       "      <td>363</td>\n",
       "      <td>2.761420</td>\n",
       "      <td>2.774290</td>\n",
       "      <td>2.844834</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    fx0d5_R   fx1d5_R   fx2d5_R     fx3_R     fx5_R     fx7_R   fx0d5_S  \\\n",
       "0  0.007299  0.006626  0.000968  0.023378  0.023553  0.006339  0.007219   \n",
       "1  0.003416  0.006184  0.001155  0.023907  0.013409  0.005977  0.003368   \n",
       "2  0.003490  0.004380  0.000786  0.018111  0.011143  0.005009  0.003484   \n",
       "3  0.002984  0.002304  0.000533  0.019345  0.014027  0.004023  0.002979   \n",
       "4  0.004993  0.004015  0.001150  0.025392  0.018566  0.004693  0.004956   \n",
       "\n",
       "    fx1d5_S   fx2d5_S     fx3_S  ...       fx3_T     fx5_T     fx7_T  \\\n",
       "0  0.006553  0.000958  0.023122  ...    0.022347  0.022515  0.006059   \n",
       "1  0.006097  0.001139  0.023569  ...    0.022888  0.012837  0.005722   \n",
       "2  0.004373  0.000785  0.018082  ...    0.017678  0.010877  0.004889   \n",
       "3  0.002300  0.000532  0.019312  ...    0.018814  0.013642  0.003913   \n",
       "4  0.003986  0.001141  0.025204  ...    0.024655  0.018027  0.004557   \n",
       "\n",
       "   Freq_Gen  CC_bus   I_R_rms   I_S_rms   I_T_rms  Load  Class  \n",
       "0     43.85     369  2.906343  2.920356  2.986445     0      1  \n",
       "1     43.87     368  2.885150  2.896358  2.962763     0      1  \n",
       "2     43.89     367  2.851384  2.863890  2.935414     0      1  \n",
       "3     43.91     365  2.819084  2.827510  2.900116     0      1  \n",
       "4     43.93     363  2.761420  2.774290  2.844834     0      1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unwanteFeatures = ['idx', 'fx1_R', 'fx1_S', 'fx1_T', 'Freq_Rated', 'Power']\n",
    "dataset_important_features = dataset.drop(unwanteFeatures, axis=1)\n",
    "\n",
    "dataset_important_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X are the inputs and y the outputs:\n",
    "\n",
    "X = dataset_important_features.values[:,:-1]\n",
    "y = dataset_important_features.values[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data with standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std_scaler = StandardScaler();\n",
    "std_scaler.fit(X)\n",
    "\n",
    "X = std_scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with 10-fold Cross Validation, tensorflow and keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your own MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = keras.Sequential([\n",
    "    keras.layers.Dense(units=10, input_shape=(X_train.shape[1],), activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(units=np.unique(y).size, activation=tf.nn.softmax),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define, optimzer, loss and mectrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.compile(optimizer=keras.optimizers.Adam(), \n",
    "            loss='sparse_categorical_crossentropy', \n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1084/1084 [==============================] - 0s 129us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "1084/1084 [==============================] - 0s 106us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "1084/1084 [==============================] - 0s 121us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "1084/1084 [==============================] - 0s 136us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "1084/1084 [==============================] - 0s 102us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "1084/1084 [==============================] - 0s 111us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "1084/1084 [==============================] - 0s 144us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "1084/1084 [==============================] - 0s 110us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "1084/1084 [==============================] - 0s 110us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "1084/1084 [==============================] - 0s 117us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "1084/1084 [==============================] - 0s 111us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "1084/1084 [==============================] - 0s 105us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "1084/1084 [==============================] - 0s 107us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "1084/1084 [==============================] - 0s 95us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 15/1000\n",
      "1084/1084 [==============================] - 0s 131us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "1084/1084 [==============================] - 0s 113us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 17/1000\n",
      "1084/1084 [==============================] - 0s 110us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 18/1000\n",
      "1084/1084 [==============================] - 0s 101us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 19/1000\n",
      "1084/1084 [==============================] - 0s 103us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 20/1000\n",
      "1084/1084 [==============================] - 0s 112us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 21/1000\n",
      "1084/1084 [==============================] - 0s 122us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 22/1000\n",
      "1084/1084 [==============================] - 0s 100us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 23/1000\n",
      "1084/1084 [==============================] - 0s 135us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 24/1000\n",
      "1084/1084 [==============================] - 0s 124us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 25/1000\n",
      "1084/1084 [==============================] - 0s 175us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 26/1000\n",
      "1084/1084 [==============================] - 0s 102us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 27/1000\n",
      "1084/1084 [==============================] - 0s 124us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 28/1000\n",
      "1084/1084 [==============================] - 0s 131us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 29/1000\n",
      "1084/1084 [==============================] - 0s 209us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 30/1000\n",
      "1084/1084 [==============================] - 0s 125us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 31/1000\n",
      "1084/1084 [==============================] - 0s 121us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 32/1000\n",
      "1084/1084 [==============================] - 0s 111us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 33/1000\n",
      "1084/1084 [==============================] - 0s 220us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 34/1000\n",
      "1084/1084 [==============================] - 0s 124us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 35/1000\n",
      "1084/1084 [==============================] - 0s 100us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 36/1000\n",
      "1084/1084 [==============================] - 0s 118us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 37/1000\n",
      "1084/1084 [==============================] - 0s 110us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 38/1000\n",
      "1084/1084 [==============================] - 0s 112us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 39/1000\n",
      "1084/1084 [==============================] - 0s 115us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 40/1000\n",
      "1084/1084 [==============================] - 0s 115us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 41/1000\n",
      "1084/1084 [==============================] - 0s 121us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 42/1000\n",
      "1084/1084 [==============================] - 0s 174us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 43/1000\n",
      "1084/1084 [==============================] - 0s 227us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 44/1000\n",
      "1084/1084 [==============================] - 0s 287us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 45/1000\n",
      "1084/1084 [==============================] - 0s 247us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 46/1000\n",
      "1084/1084 [==============================] - 0s 119us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 47/1000\n",
      "1084/1084 [==============================] - 0s 103us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 48/1000\n",
      "1084/1084 [==============================] - 0s 109us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 49/1000\n",
      "1084/1084 [==============================] - 0s 112us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 50/1000\n",
      "1084/1084 [==============================] - 0s 107us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 51/1000\n",
      "1084/1084 [==============================] - 0s 142us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 52/1000\n",
      "1084/1084 [==============================] - 0s 120us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 53/1000\n",
      "1084/1084 [==============================] - 0s 104us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 54/1000\n",
      "1084/1084 [==============================] - 0s 118us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 55/1000\n",
      "1084/1084 [==============================] - 0s 131us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 56/1000\n",
      "1084/1084 [==============================] - 0s 115us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 57/1000\n",
      "1084/1084 [==============================] - 0s 129us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 58/1000\n",
      "1084/1084 [==============================] - 0s 103us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 59/1000\n",
      "1084/1084 [==============================] - 0s 106us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 60/1000\n",
      "1084/1084 [==============================] - 0s 120us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 61/1000\n",
      "1084/1084 [==============================] - 0s 127us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 62/1000\n",
      "1084/1084 [==============================] - 0s 137us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 63/1000\n",
      "1084/1084 [==============================] - 0s 102us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 64/1000\n",
      "1084/1084 [==============================] - 0s 121us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 65/1000\n",
      "1084/1084 [==============================] - 0s 156us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 66/1000\n",
      "1084/1084 [==============================] - 0s 105us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 67/1000\n",
      "1084/1084 [==============================] - 0s 128us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 68/1000\n",
      "1084/1084 [==============================] - 0s 101us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 69/1000\n",
      "1084/1084 [==============================] - 0s 112us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 70/1000\n",
      "1084/1084 [==============================] - 0s 117us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 71/1000\n",
      "1084/1084 [==============================] - 0s 110us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 72/1000\n",
      "1084/1084 [==============================] - 0s 115us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 73/1000\n",
      "1084/1084 [==============================] - 0s 105us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 74/1000\n",
      "1084/1084 [==============================] - 0s 120us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 75/1000\n",
      "1084/1084 [==============================] - 0s 110us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 76/1000\n",
      "1084/1084 [==============================] - 0s 122us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 77/1000\n",
      "1084/1084 [==============================] - 0s 120us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 78/1000\n",
      "1084/1084 [==============================] - 0s 117us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 79/1000\n",
      "1084/1084 [==============================] - 0s 116us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 80/1000\n",
      "1084/1084 [==============================] - 0s 149us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 81/1000\n",
      "1084/1084 [==============================] - 0s 117us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 82/1000\n",
      "1084/1084 [==============================] - 0s 104us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 83/1000\n",
      "1084/1084 [==============================] - 0s 106us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 84/1000\n",
      "1084/1084 [==============================] - 0s 138us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 85/1000\n",
      "1084/1084 [==============================] - 0s 119us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 86/1000\n",
      "1084/1084 [==============================] - 0s 116us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 87/1000\n",
      "1084/1084 [==============================] - 0s 111us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 88/1000\n",
      "1084/1084 [==============================] - 0s 131us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 89/1000\n",
      "1084/1084 [==============================] - 0s 98us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 90/1000\n",
      "1084/1084 [==============================] - 0s 152us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 91/1000\n",
      "1084/1084 [==============================] - 0s 120us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 92/1000\n",
      "1084/1084 [==============================] - 0s 125us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 93/1000\n",
      "1084/1084 [==============================] - 0s 138us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 94/1000\n",
      "1084/1084 [==============================] - 0s 143us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 95/1000\n",
      "1084/1084 [==============================] - 0s 114us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 96/1000\n",
      "1084/1084 [==============================] - 0s 111us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 97/1000\n",
      "1084/1084 [==============================] - 0s 132us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 98/1000\n",
      "1084/1084 [==============================] - 0s 107us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 99/1000\n",
      "1084/1084 [==============================] - 0s 108us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 100/1000\n",
      "1084/1084 [==============================] - 0s 124us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 101/1000\n",
      "1084/1084 [==============================] - 0s 141us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 102/1000\n",
      "1084/1084 [==============================] - 0s 144us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 103/1000\n",
      "1084/1084 [==============================] - 0s 130us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 104/1000\n",
      "1084/1084 [==============================] - 0s 139us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 105/1000\n",
      "1084/1084 [==============================] - 0s 114us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 106/1000\n",
      "1084/1084 [==============================] - 0s 107us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 107/1000\n",
      "1084/1084 [==============================] - 0s 144us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 108/1000\n",
      "1084/1084 [==============================] - 0s 116us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 109/1000\n",
      "1084/1084 [==============================] - 0s 119us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 110/1000\n",
      "1084/1084 [==============================] - 0s 120us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 111/1000\n",
      "1084/1084 [==============================] - 0s 117us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 112/1000\n",
      "1084/1084 [==============================] - 0s 125us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 113/1000\n",
      "1084/1084 [==============================] - 0s 158us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 114/1000\n",
      "1084/1084 [==============================] - 0s 119us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 115/1000\n",
      "1084/1084 [==============================] - 0s 108us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 116/1000\n",
      "1084/1084 [==============================] - 0s 114us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 117/1000\n",
      "1084/1084 [==============================] - 0s 115us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 118/1000\n",
      "1084/1084 [==============================] - 0s 129us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 119/1000\n",
      "1084/1084 [==============================] - 0s 128us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 120/1000\n",
      "1084/1084 [==============================] - 0s 111us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 121/1000\n",
      "1084/1084 [==============================] - 0s 113us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 122/1000\n",
      "1084/1084 [==============================] - 0s 118us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 123/1000\n",
      "1084/1084 [==============================] - 0s 121us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 124/1000\n",
      "1084/1084 [==============================] - 0s 104us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 125/1000\n",
      "1084/1084 [==============================] - 0s 109us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 126/1000\n",
      "1084/1084 [==============================] - 0s 125us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 127/1000\n",
      "1084/1084 [==============================] - 0s 133us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 128/1000\n",
      "1084/1084 [==============================] - 0s 120us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 129/1000\n",
      "1084/1084 [==============================] - 0s 112us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 130/1000\n",
      "1084/1084 [==============================] - 0s 111us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 131/1000\n",
      "1084/1084 [==============================] - 0s 111us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 132/1000\n",
      "1084/1084 [==============================] - 0s 117us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 133/1000\n",
      "1084/1084 [==============================] - 0s 123us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 134/1000\n",
      "1084/1084 [==============================] - 0s 112us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 135/1000\n",
      "1084/1084 [==============================] - 0s 134us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 136/1000\n",
      "1084/1084 [==============================] - 0s 124us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 137/1000\n",
      "1084/1084 [==============================] - 0s 115us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 138/1000\n",
      "1084/1084 [==============================] - 0s 113us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 139/1000\n",
      "1084/1084 [==============================] - 0s 110us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 140/1000\n",
      "1084/1084 [==============================] - 0s 117us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 141/1000\n",
      "1084/1084 [==============================] - 0s 121us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 142/1000\n",
      "1084/1084 [==============================] - 0s 122us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 143/1000\n",
      "1084/1084 [==============================] - 0s 136us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 144/1000\n",
      "1084/1084 [==============================] - 0s 160us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 145/1000\n",
      "1084/1084 [==============================] - 0s 111us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 146/1000\n",
      "1084/1084 [==============================] - 0s 125us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 147/1000\n",
      "1084/1084 [==============================] - 0s 114us/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 148/1000\n",
      " 928/1084 [========================>.....] - ETA: 0s - loss: nan - acc: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-03081c5bb8f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    212\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2961\u001b[0m         \u001b[0mtensor_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2962\u001b[0m         array_vals.append(np.asarray(value,\n\u001b[0;32m-> 2963\u001b[0;31m                                      dtype=tensor_type.as_numpy_dtype))\n\u001b[0m\u001b[1;32m   2964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2965\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \"\"\"\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mlp.fit(X_train, y_train, a=1000, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with 10-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an MLP:\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlpCLf = MLPClassifier(solver='lbfgs', alpha=1e-5, learning_rate='adaptive', learning_rate_init = 0.1,\n",
    "                    max_iter=1300, momentum=0.3, activation = 'tanh', power_t=0.5,\n",
    "                    hidden_layer_sizes=(10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_prepared' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0884d708a585>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlpCLf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_prepared\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_prepared' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a cross validation object:\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_pred = cross_val_predict(mlpCLf, X_prepared, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def percentage_confusion_matrix (mat):\n",
    "    return np.around(100*(mat / mat.sum(axis=1)[:,None]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(percentage_confusion_matrix(metrics.confusion_matrix(y_pred, y)))\n",
    "print(metrics.accuracy_score(y_pred, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = metrics.confusion_matrix(y_pred, y)\n",
    "\n",
    "plt.matshow((mat / mat.sum(axis=1)[:,None]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
